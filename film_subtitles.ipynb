{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5801044-908e-462e-88f5-3e17480ddb1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Загрузка данных и библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22dbc16c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.training_args_tf because of the following error (look up to see its traceback):\nmodule 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1087\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\training_args_tf.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcached_property\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_backends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdebug_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m from .trainer_utils import (\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mEvaluationStrategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\trainer_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimization_options\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptimizationOptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_example_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetching_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy_to_device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\parsing_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mragged\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mragged_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m# go/tf-wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mragged\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mragged_math_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspecial_math_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;31m# go/tf-wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf2xla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_xla_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\compiler\\tf2xla\\ops\\gen_xla_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_fallback_dispatch_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_type_based_api_dispatcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-32a2c211e7cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDatasetDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFAutoModelForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#nltk.download('stopwords')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m                 \u001b[1;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.training_args_tf because of the following error (look up to see its traceback):\nmodule 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "import srt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from datasets import Dataset,DatasetDict\n",
    "from transformers import TFAutoModelForSequenceClassification,AutoTokenizer, TFTrainingArguments, TFTrainer\n",
    "import tensorflow as tf\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc787e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels = pd.read_excel('movies_labels.xlsx', names=['id', 'movie', 'level']).drop('id', axis=1)\n",
    "subtitles_files = load_files('Subtitles/', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_labels.info())\n",
    "movie_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb50f7-00f8-484b-b5ef-dd6949455d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = pd.DataFrame(data={'data': subtitles_files.data, \n",
    "                          'filenames': subtitles_files.filenames})\n",
    "subtitles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae40dd",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8a04c-35c7-4f81-99b7-b672346cd709",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c6eee-eb95-41c4-9147-1e99ae0b9c40",
   "metadata": {},
   "source": [
    "deleted :\n",
    "* Crown, The S01E03 - Windsor.en.FORCED.srt\n",
    "* Crown, The S01E05 - Smoke and Mirrors.en.FORCED.srt\n",
    "* Crown, The S01E07 - Scientia Potentia Est.en.FORCED.srt\n",
    "* Crown, The S01E10 - Gloriana.en.FORCED.srt\n",
    "\n",
    "reformatted:\n",
    "* Suits season 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348771ca-6831-49aa-8796-b90e5ee60208",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a28ca0-b935-4c07-b4ec-baeb6fb636ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles['data'] = subtitles['data'].str.decode('ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a42e3-99c5-498e-84ca-1efe7f812c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_and_level(row):\n",
    "    level = row.split('\\\\')[0][10:]\n",
    "    name = row.split('\\\\')[1][:-4]\n",
    "    return pd.Series([name, level])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fb158-4d9a-495d-8ab0-ec51ebeccb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles[['movie', 'level']] = subtitles['filenames'].apply(get_name_and_level)\n",
    "subtitles = subtitles.drop('filenames', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6979b-1f13-4fd2-ac5a-d3085fa0a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles['movie'] = subtitles['movie'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d9c94-3936-4029-960b-bf3cc452d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269e702-8266-4dd6-8665-d6f8b98d7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75cd86-890f-47e0-a574-044901ed7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles[subtitles['data'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7e342-8da5-4572-8d51-c7070a5c0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = subtitles.drop(subtitles[subtitles['data'].duplicated()].index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a97ea-8cfe-492b-bc1c-044c86379ec9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## movie_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba287eab-3c7b-4687-96b3-ad3a20a40802",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a1d9d-c6b5-48a0-a0da-b3fe7cc89cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d63c0-cd94-4c9a-ab08-2585aa735a72",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d82476-e054-4168-aa23-e9c699b54e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels['movie'] = movie_labels['movie'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c6b76-b179-430c-99ff-d302aea2b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3febf87a-57d8-425c-8423-a29e1ec59137",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels = movie_labels.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3cedc-c9be-4d48-828c-0838043f0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_labels[movie_labels['movie'].duplicated(keep=False)].index)\n",
    "movie_labels[movie_labels['movie'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8122dcf-17e5-4d4d-83bb-dd42d9e22b24",
   "metadata": {},
   "source": [
    "https://moviesbylevels.wordpress.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515ab0d-ee0a-4bdc-a78e-7192018c261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels = movie_labels.drop([84, 99], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061db28-9022-4be0-89ce-e686e6ba0fa2",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43935d1d-e82e-47ed-81d1-c034224de082",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels = movie_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa778c8-1a1c-414f-a779-b00dccf21d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels['level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d6c41-3121-422d-8689-830d74948d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = movie_labels[movie_labels['level'] == 'A2/A2+, B1'].index\n",
    "movie_labels[movie_labels['level'] == 'A2/A2+, B1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148b844-27af-4896-9ca2-55050d088f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels['level'].iloc[indexes[0]] = 'A2'\n",
    "movie_labels['level'].iloc[indexes[1]] = 'B1'\n",
    "movie_labels['level'].iloc[indexes[2]] = 'B1'\n",
    "movie_labels['level'].iloc[indexes[3]] = 'A2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e55ef-980b-4f6c-8152-3afb3a9d98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = movie_labels[movie_labels['level'] == 'B1, B2'].index\n",
    "movie_labels[movie_labels['level'] == 'B1, B2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7ca8e-e860-40c6-95e3-78c1c6cbe955",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels['level'].iloc[indexes[0]] = 'B1'\n",
    "movie_labels['level'].iloc[indexes[1]] = 'B1'\n",
    "movie_labels['level'].iloc[indexes[2]] = 'B1'\n",
    "movie_labels['level'].iloc[indexes[3]] = 'B2'\n",
    "movie_labels['level'].iloc[indexes[4]] = 'B2'\n",
    "movie_labels['level'].iloc[indexes[5]] = 'B2'\n",
    "movie_labels['level'].iloc[indexes[6]] = 'B2'\n",
    "movie_labels['level'].iloc[indexes[7]] = 'B1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea94ee8-5544-4435-914d-30404aaec31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels['level'] = movie_labels['level'].str.replace('A2/A2+', 'A2', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee3a13-c28d-4984-9de3-92d6330ace42",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_labels['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92002f-328d-4fb8-8b10-d47566f7abe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea5739-c5ea-4f65-9348-9f44076949a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(subtitles, movie_labels, how='outer', on=['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dffc9-a8d2-4e59-b058-2f9db417b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba1c19-30ea-4af0-ae6f-9e2ef68a2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe())\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d430f-5df3-4d06-8180-72571e362c64",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220e19c-9f68-4c98-ab0a-717c0735ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['data'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2a7d2-60e3-44fc-b630-db7b4f883861",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### its_a_wonderful_life(1946)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033b1e8-b9cd-4201-b2cb-40e52c22d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('wonderful')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda02219-7521-48fb-85b4-de92aad61b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_x'].iloc[207] = df['level_y'].iloc[276]\n",
    "df = df.drop(276, axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3664f-f0a6-46d7-a26b-4fc8667b581e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### he secret life of pets.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248aba5-51ae-4962-9a5f-8e9ee2a01deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('pet')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2480d9-7bea-48ba-9459-5ce569c66986",
   "metadata": {},
   "source": [
    "https://subscene.com/subtitles/the-secret-life-of-pets/english/1440256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7842c-2603-462f-8d20-683e08a272e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = open('Missing_subtitles/The.Secret.Life.of.Pets.2016.720p.BRRip.x264.AAC-ETRG.srt', 'r', encoding='ISO-8859-1')\n",
    "df['data'].iloc[274] = subs.read()\n",
    "subs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd940a-b548-4cb4-808d-b8442b64d8c4",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### up (2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05322603-5ce9-4e55-b2bc-7b3b5986b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('up')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b19bb-60b6-48bc-a062-20dbb94db572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_x'].iloc[267] = df['level_y'].iloc[275]\n",
    "df = df.drop(275, axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd300d-f65f-4466-9980-f7367437e014",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### glass onion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c829e-d11a-4eb9-9606-f4a2618a79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('onion')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b177bc9-71ed-45dc-812c-26e223ef1264",
   "metadata": {},
   "source": [
    "https://subscene.com/subtitles/glass-onion-a-knives-out-mystery/english/2960299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9eb4e4-79b5-4c9b-ac96-9b9afd47a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = open('Missing_subtitles/Glass.Onion.A Knives.Out.Mystery.2022.1080p.NF.WEB-DL.DDP5.1.Atmos.x264.srt', 'r',  encoding='ISO-8859-1')\n",
    "df['data'].iloc[275] = subs.read()\n",
    "subs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fddbe0-15bd-4efb-b826-879314caa17e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### matilda(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09687f-9cff-4baf-bbcd-7cb6cb53efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('matilda')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cfb74-f78e-4060-b818-6e2943b335cb",
   "metadata": {},
   "source": [
    "https://subscene.com/subtitles/roald-dahls-matilda-the-musical/english/2968073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb3441-76d6-4afb-beba-d4d127440e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = open(\"Missing_subtitles/Roald Dahl's Matilda the Musical (2022).srt\", 'r',  encoding='ISO-8859-1')\n",
    "df['data'].iloc[276] = subs.read()\n",
    "subs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a9b96-0eeb-43f1-b747-d6de87db9420",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### bullet train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6690d-27ba-42e3-a602-885bbdec58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('train')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e71809-1789-4c9f-a55f-392e6eee6e2c",
   "metadata": {},
   "source": [
    "https://subscene.com/subtitles/bullet-train/english/3035799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627e845-e4b7-465a-a09e-5036e6cf9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = open('Missing_subtitles/Bullet.Train.Eng.2022.NoHI.srt', 'r',  encoding='ISO-8859-1')\n",
    "df['data'].iloc[277] = subs.read()\n",
    "subs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a1b75-b471-4d73-a412-bc0d8b0d8e14",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### thor: love and thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7befc8-2b54-43b1-8e3a-4ab5def176bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('thor')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f630e-ffa5-498f-8c01-5b6b2652021f",
   "metadata": {},
   "source": [
    "https://subscene.com/subtitles/thor-love-and-thunder/english/2878411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c8615-85f2-44b0-ac68-7b20ddfcae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = open('Missing_subtitles/Thor.Love.and.Thunder.2022.1080p.WEBRip.X264.DD5.1.srt', 'r',  encoding='ISO-8859-1')\n",
    "df['data'].iloc[278] = subs.read()\n",
    "subs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb597218-0608-4899-9893-aae534dfb9c0",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### lightyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfe667-5b88-4bed-bb06-f3dfbc1aade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('lightyear')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b84e12-f0ba-4c94-ada1-7b37118a1b3d",
   "metadata": {},
   "source": [
    "https://subscene.com/subtitles/lightyear/english/2857387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8faf3-f3a4-40a7-998c-84476e25f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = open('Missing_subtitles/Lightyear.2022.WEBRip.x264-PS.srt', 'r',  encoding='ISO-8859-1')\n",
    "df['data'].iloc[279] = subs.read()\n",
    "subs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc78746-4f39-4dc7-b270-06535d05a80c",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### the grinch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909096d6-6ab2-431b-a4a4-0afe89404420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['movie'].str.contains('grinch')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9811625-d30d-4482-944a-5bf82da02c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(280, axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfecdf-9806-4fa1-82f9-6b1db5556696",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39feec62-5cdf-496c-9084-2621612280bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159835a3-2301-4daa-b863-eb5e4f4de746",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### moive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859e8d0-75b0-4adb-91ea-97f15bb10edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a430016-a0e1-4b75-b53e-7e90b0f2e51d",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b526446-87ed-47ea-92d9-3ad5a09e15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['level_x'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08046f41-a3dc-4867-ac59-3c0a7e44c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_x'] = df['level_x'].fillna(df['level_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d96d5-d895-437e-b116-e45cb3de897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['level_y'].unique())\n",
    "df['level_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e1eac-78b0-4483-8ec2-86f6479b1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = df[(df['level_x'] == 'Unlabeled') & (df['level_y'].isna())].index\n",
    "df[(df['level_x'] == 'Unlabeled') & (df['level_y'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6840f-04f6-49d2-b5a4-adc19b99016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_x'].iloc[indexes[0]] = 'B2'\n",
    "df['level_x'].iloc[indexes[1]] = 'B2'\n",
    "df['level_x'].iloc[indexes[2]] = 'A2'\n",
    "df['level_x'].iloc[indexes[3]] = 'A2' #A1 not present in dataset\n",
    "df['level_x'].iloc[indexes[4]] = 'A2'\n",
    "df['level_x'].iloc[indexes[5]] = 'B2'\n",
    "df['level_x'].iloc[indexes[6]] = 'B2'\n",
    "df['level_x'].iloc[indexes[7]] = 'B2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9eae4-2d2d-49de-8a5b-b2507709fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[23][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f723c-abfd-4a42-b129-0fca0e54137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_x'] = df[['level_x', 'level_y']].apply(lambda x: x['level_x'] if x['level_x'] != 'Unlabeled' else x['level_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34144b84-0990-4d58-8521-57332c314726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf90049-9963-4aeb-8f1b-bf98469fa641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('level_y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31339a8b-1aec-4877-b6ca-7f995b9e51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'level_x': 'level'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3477789-5412-43d8-a529-6ccb21e85a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d7e22-8625-443a-adb8-2cb5c50a011d",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## subtitle processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27d74f-57f5-4dfc-9524-c3921cb4b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_subtitles(data):\n",
    "    subtitle_generator = srt.parse(data, ignore_errors=True);\n",
    "    subs = list(subtitle_generator)\n",
    "    subs_text = []\n",
    "    for i in range(len(subs)):\n",
    "        subs_text.append(subs[i].content)\n",
    "    \n",
    "    return(' '.join(subs_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9844245-41ee-4e86-a4ba-914dfd3a2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594d82a9-1c8d-427f-a5e4-10430c7cee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_clean(data):\n",
    "    data_tokenized = nltk.word_tokenize(data)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    data_cleaned = [word for word in data_tokenized if word.lower() not in stopwords]\n",
    "    data_cleaned = [word.lower() for word in data_cleaned if word.isalpha()]\n",
    "    lemm = WordNetLemmatizer()\n",
    "    data_lemmatized = [lemm.lemmatize(w) for w in data_cleaned]\n",
    "    return data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2625a7b-ee8b-4623-8119-4ab281433827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'] = df['data'].apply(parse_subtitles)\n",
    "df['data'] = df['data'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee0d59-1197-4d41-886c-9b904ff73a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'] = df['data'].apply(tokenize_and_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f798410-5f02-47fb-a241-ecf6d52d7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_a2 = df[df['level'] == 'A2']['data'].values\n",
    "level_a2 = np.concatenate(level_a2, axis=0)\n",
    "level_b1 = df[df['level'] == 'B1']['data'].values\n",
    "level_b1 = np.concatenate(level_b1, axis=0)\n",
    "level_b2 = df[df['level'] == 'B2']['data'].values\n",
    "level_b2 = np.concatenate(level_b2, axis=0)\n",
    "level_c1 = df[df['level'] == 'C1']['data'].values\n",
    "level_c1 = np.concatenate(level_c1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c586535-ba48-4db2-9f6a-ff1f1413a789",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013a0e5-97e2-4301-aa61-caceeffcfeda",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57988b-991a-493b-bf9b-5b1b0a16bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_counts = df.groupby('level')['level'].count()\n",
    "fig, ax = plt.subplots(figsize = (12,12))\n",
    "ax.grid(False)\n",
    "fig.patch.set_facecolor('w')\n",
    "level_counts.plot(kind='pie', autopct='%1.1f%%',  textprops={'fontsize': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b957b2-4c95-491b-af8b-bcc88a5df31b",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66cad6-c20c-4f0c-b9ef-6e1a03d45daa",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8685ca-1199-4121-a3f4-3f349a817f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 20))\n",
    "wordcloud = WordCloud(collocations=False, stopwords=STOPWORDS, background_color='black').generate(' '.join(level_a2))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title('A2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e576b-c325-462b-8bd9-52926bf60b3e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad9651-c27a-4506-bc5e-ea704c885505",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 20))\n",
    "wordcloud = WordCloud(collocations=False, stopwords=STOPWORDS, background_color='black').generate(' '.join(level_b1))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title('B1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9659d7b-cefd-42d9-987f-d71470d41d38",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a7dc6-c2b8-4716-b951-fe25b06efb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 20))\n",
    "wordcloud = WordCloud(collocations=False, stopwords=STOPWORDS, background_color='black').generate(' '.join(level_b2))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title('B2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb0b74-98df-4261-9a01-458ae0c7632b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f415e2-c813-4204-a063-cf63eb4c6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 20))\n",
    "wordcloud = WordCloud(collocations=False, stopwords=STOPWORDS, background_color='black').generate(' '.join(level_c1))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title('C1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cfbdf-2d36-48fc-a2e9-f3756e3ae393",
   "metadata": {},
   "source": [
    "# Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c4705-c51a-4ec8-b574-c73960edd595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1022cec-a54c-4368-8f18-96df47258f6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-trained transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b29cad-8a62-4d5f-80a6-9836660fd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'] = df['data'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bff2f-721b-45cd-9f1a-7d5eb8b02451",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df.drop('movie', axis=1))\n",
    "ds = ds.rename_column('level', 'label')\n",
    "ds = ds.class_encode_column(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24007794-0f37-4545-a898-eafea17e8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e6b71-ab52-43bb-b7cb-8a073aa8b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'microsoft/deberta-v3-large'\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f77993-30c7-4bf3-86c8-b886bce7bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokz_func(data):\n",
    "    return tokz(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7531598b-5e15-4706-9f3d-39ac49719130",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tokenized = ds.map(tokz_func, batched=True, remove_columns='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e30b6-3a24-4e30-a5c4-47effd3fcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_split = ds_tokenized.train_test_split(test_size=0.2, stratify_by_column='label', seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64af13b-da85-4578-b269-c717212b08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(eval_pred):\n",
    "    return {'pearson': np.corrcoef(*eval_pred)[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c879295-7bd1-4f5b-adee-340653f506a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "bs = 128\n",
    "args = TFTrainingArguments('outputs', learning_rate=8e-5, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True, evaluation_strategy=\"epoch\",\n",
    "                         per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2, num_train_epochs=4, weight_decay=0.01, report_to='none')\n",
    "trainer = TFTrainer(model, args, train_dataset=ds_split['train'], eval_dataset=ds_split['test'], compute_metrics=correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d6dba-852c-496a-8197-2c3874e16a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    " # my output was => ['/device:CPU:0']\n",
    " # good output must be => ['/device:CPU:0', '/device:GPU:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d9724-afa5-4d64-aa46-2e4146dfc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19860da-b94b-4495-b790-7a1e6544218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution() \n",
    "\n",
    "\n",
    "\n",
    "# Explicitly place tensors on the DirectML device \n",
    "\n",
    "with tf.device('/DML:0'): \n",
    "    a = tf.constant([1.0, 2.0, 3.0]) \n",
    "    b = tf.constant([4.0, 5.0, 6.0]) \n",
    "\n",
    "\n",
    "\n",
    "c = tf.add(a, b) \n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae338b-546e-4f9b-818b-14f32b5f092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print (sys.version)\n",
    " # 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    " # my output was => 1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8c43f-fd9a-4a7a-aff0-29f1f220171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
